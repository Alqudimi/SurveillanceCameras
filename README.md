# نظام الإنذار والأمان الذكي المحسن

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![Keras](https://img.shields.io/badge/Keras-Deep%20Learning-red)
![Flask](https://img.shields.io/badge/Flask-API-green)
![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-blue) 
---
##  جدول المحتويات

- [نظام الإنذار والأمان الذكي المحسن](#نظام-الإنذار-والأمان-الذكي-المحسن)
  - [ جدول المحتويات](#-جدول-المحتويات)
  - [ فكرة المشروع والسيناريو الواقعي](#-فكرة-المشروع-والسيناريو-الواقعي)
  - [ مصدر البيانات المستخدم](#-مصدر-البيانات-المستخدم)
    - [1. بيانات تصنيف العنف](#1-بيانات-تصنيف-العنف)
    - [2. بيانات حوادث المرور](#2-بيانات-حوادث-المرور)
  - [ بنية النموذج والخوارزميات](#-بنية-النموذج-والخوارزميات)
    - [النماذج الأساسية](#النماذج-الأساسية)
    - [تفاصيل بنية النموذج (مثال لنموذج MobileNet مع التعلم بالنقل):](#تفاصيل-بنية-النموذج-مثال-لنموذج-mobilenet-مع-التعلم-بالنقل)
    - [الخوارزميات وتقنيات المعالجة المسبقة](#الخوارزميات-وتقنيات-المعالجة-المسبقة)
    - [بنية مدير التصنيف (EnhancedClassificationManager)](#بنية-مدير-التصنيف-enhancedclassificationmanager)
  - [ خطوات التشغيل](#-خطوات-التشغيل)
    - [1. المتطلبات الأساسية](#1-المتطلبات-الأساسية)
    - [2. تثبيت المكتبات](#2-تثبيت-المكتبات)
    - [3. إعداد متغيرات البيئة](#3-إعداد-متغيرات-البيئة)
    - [4. تشغيل الخادم الخلفي (API)](#4-تشغيل-الخادم-الخلفي-api)
    - [5. تشغيل الواجهة الأمامية (Frontend)](#5-تشغيل-الواجهة-الأمامية-frontend)
  - [ النتائج](#-النتائج)
    - [1. دقة التصنيف (Accuracy)](#1-دقة-التصنيف-accuracy)
    - [2. مصفوفة الالتباس (Confusion Matrix)](#2-مصفوفة-الالتباس-confusion-matrix)
    - [3. صور مفصلة للنتائج (أمثلة)](#3-صور-مفصلة-للنتائج-أمثلة)
  - [ التحسينات الممكنة مستقبلاً](#-التحسينات-الممكنة-مستقبلاً)
    - [1. تحسين النماذج والخوارزميات](#1-تحسين-النماذج-والخوارزميات)
    - [2. تحسينات الأداء وقابلية التوسع](#2-تحسينات-الأداء-وقابلية-التوسع)
    - [3. تعزيز التنبيهات والإشعارات](#3-تعزيز-التنبيهات-والإشعارات)
    - [4. تحسينات واجهة المستخدم وتجربة المستخدم](#4-تحسينات-واجهة-المستخدم-وتجربة-المستخدم)
    - [5. الأمان والخصوصية](#5-الأمان-والخصوصية)
    - [6. التكامل مع أنظمة أخرى](#6-التكامل-مع-أنظمة-أخرى)
  - [التقنيات المستخدمة](#التقنيات-المستخدمة)

---
---
## فكرة المشروع والسيناريو الواقعي

يهدف هذا المشروع إلى تطوير نظام ذكي ومتكامل قادر على تحليل الصور الواردة من مصادر مختلفة (مثل كاميرات المراقبة) لتحديد أربعة أنواع رئيسية من الأحداث الخطرة: حركات المرور غير الطبيعية (مثل الازدحامات أو توقف حركة السير)، الحرائق، الحوادث، وأعمال العنف. في عالم يزداد تعقيدًا وتتزايد فيه الحاجة إلى أنظمة أمان استباقية، يصبح الرصد الآلي لهذه الأحداث أمرًا بالغ الأهمية. يعالج هذا النظام الحاجة الملحة لتقليل زمن الاستجابة للطوارئ، وتحسين كفاءة عمليات المراقبة، وتوفير بيئة أكثر أمانًا للمجتمعات والأفراد.

**السيناريو الواقعي:** تخيل مدينة ذكية حيث تنتشر كاميرات المراقبة في الشوارع، والمباني، والمرافق العامة. بدلاً من الاعتماد على المراقبة البشرية المستمرة، والتي قد تكون مكلفة وغير فعالة على مدار الساعة، يقوم هذا النظام بتحليل تدفقات الفيديو والصور بشكل آلي. عند اكتشاف أي من الأحداث الأربعة المحددة (حركة مرور غير طبيعية، حريق، حادث، عنف)، يقوم النظام على الفور بتصنيف الحدث، وتحديد مستوى خطورته، ثم إرسال تنبيهات فورية ومفصلة إلى الجهات المعنية (مثل الشرطة، الإطفاء، الإسعاف، أو فرق الصيانة). يمكن أن تتضمن هذه التنبيهات معلومات مثل نوع الحدث، موقعه، مستوى الثقة في التصنيف، وحتى صورًا أو مقاطع فيديو للحدث. هذا يتيح استجابة أسرع وأكثر دقة، مما يقلل من الخسائر البشرية والمادية، ويحسن من إدارة الأزمات بشكل عام.

## مصدر البيانات المستخدم

لضمان فعالية النماذج المدربة، تم الاعتماد على مجموعتي بيانات رئيسيتين من منصة Kaggle، وهما:

### 1. بيانات تصنيف العنف (Real Life Violence Situations Dataset)

-   **المصدر**: [Kaggle: Real Life Violence Situations](https://www.kaggle.com/datasets/abdulmananraja/real-life-violence-situations)
-   **الوصف**: تحتوي هذه المجموعة على صور ومقاطع فيديو تمثل سيناريوهات عنف حقيقية وغير عنيفة. تم استخدامها لتدريب نموذج قادر على التمييز بين المواقف التي تتضمن عنفًا والمواقف العادية. تعد جودة هذه البيانات وتنوعها أمرًا حاسمًا لتدريب نموذج قوي يمكنه التعرف على أشكال مختلفة من العنف في بيئات متنوعة.
-   **الفئات المستهدفة**: `violence` (عنف) و `non_violence` (غير عنف).

### 2. بيانات حوادث المرور (Traffic-Net Dataset)

-   **المصدر**: [Kaggle: Traffic-Net Dataset](https://www.kaggle.com/datasets/umairshahpirzada/traffic-net)
-   **الوصف**: تركز هذه المجموعة على سيناريوهات حركة المرور المختلفة، بما في ذلك الازدحامات، والحوادث، وحالات المرور الطبيعية. تم استخدامها لتدريب نماذج قادرة على تحليل تدفق حركة المرور وتحديد الحوادث أو الظروف غير الطبيعية. هذه البيانات ضرورية لتطوير نظام يمكنه المساهمة في إدارة حركة المرور والسلامة على الطرق.
-   **الفئات المستهدفة**: `accident` (حادث)، `dense_traffic` (مرور كثيف)، `fire` (حريق)، `sparse_traffic` (مرور خفيف).

تم اختيار هذه المجموعات بعناية لتمثيل التحديات الواقعية التي قد يواجهها النظام في بيئات المراقبة، وتوفير قاعدة بيانات كافية لتدريب نماذج تعلم عميق قوية وموثوقة.

## بنية النموذج والخوارزميات

يعتمد النظام على بنية تعلم عميق متقدمة تستخدم نماذج الشبكات العصبية التلافيفية (Convolutional Neural Networks - CNNs) المصممة خصيصًا لمهام تصنيف الصور. تم استخدام نهج التعلم بالنقل (Transfer Learning) لتدريب النماذج، حيث يتم الاستفادة من نموذج `MobileNet` المدرب مسبقًا على مجموعات بيانات كبيرة (مثل ImageNet) ثم تعديله ليناسب مهمة التصنيف المحددة للمشروع. هذا النهج يقلل بشكل كبير من وقت التدريب ويحسن من أداء النموذج، خاصة عند التعامل مع مجموعات بيانات أصغر نسبيًا.

### النماذج الأساسية

تم استخدام نموذج `MobileNet` كنموذج أساسي (Base Model) لعملية التعلم بالنقل. تم تدريب نموذجين منفصلين لضمان التخصص والدقة في التعرف على الأنماط الخاصة بكل حدث:

-   **نموذج العنف**: تم تدريبه باستخدام بنية `MobileNet` على مجموعة بيانات `Real Life Violence Situations`.
-   **نموذج الفئات الأخرى (حركات المرور، الحرائق، الحوادث)**: تم تدريبه باستخدام بنية `MobileNet` على مجموعة بيانات `Traffic-Net`.

### تفاصيل بنية النموذج (مثال لنموذج MobileNet مع التعلم بالنقل):

1.  **تحميل النموذج الأساسي**: يتم تحميل نموذج `MobileNet` المدرب مسبقًا على `ImageNet`، مع استبعاد الطبقات العلوية التي تكون خاصة بمهام التصنيف الأصلية لـ `ImageNet`.
    ```python
from tensorflow.keras.applications import MobileNet
base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    ```
2.  **تجميد الطبقات الأساسية**: يتم تجميد أوزان الطبقات التلافيفية في النموذج الأساسي لمنع تحديثها أثناء التدريب الأولي. هذا يحافظ على الميزات المستخرجة عالية المستوى التي تعلمها النموذج من `ImageNet`.
    ```python
for layer in base_model.layers:
    layer.trainable = False
    ```
3.  **إضافة طبقات علوية مخصصة**: يتم بناء مجموعة من الطبقات العلوية فوق النموذج الأساسي. تتضمن هذه الطبقات:
    -   **طبقة تسطيح (Flatten Layer)**: لتحويل مخرجات الطبقات التلافيفية إلى متجه أحادي البعد.
    -   **طبقات كثيفة (Dense Layers)**: طبقات متصلة بالكامل لتعلم الأنماط المعقدة واتخاذ قرارات التصنيف.
    -   **طبقة إسقاط (Dropout Layer)**: لمنع الإفراط في التخصيص عن طريق إسقاط نسبة عشوائية من الخلايا العصبية أثناء التدريب.
    -   **طبقة الإخراج (Output Layer)**: طبقة كثيفة بعدد خلايا عصبية يساوي عدد الفئات المستهدفة، مع دالة تفعيل `softmax` لإخراج احتمالات التصنيف.
    ```python
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten, Dense, Dropout

x = Flatten()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(NUM_CLASSES, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)
    ```
4.  **التدريب على مرحلتين (Two-Phase Training)**:
    -   **المرحلة الأولى (Warmup)**: يتم تدريب الطبقات العلوية المضافة فقط، مع تجميد النموذج الأساسي. هذا يسمح للطبقات الجديدة بالتكيف مع الميزات المستخرجة من النموذج الأساسي.
    -   **المرحلة الثانية (Fine-tuning)**: يتم إلغاء تجميد بعض الطبقات العليا من النموذج الأساسي (أو كلها) وتدريب النموذج بالكامل بمعدل تعلم منخفض جدًا. هذا يسمح للنموذج بضبط أوزانه بشكل دقيق ليتناسب بشكل أفضل مع مجموعة البيانات المحددة للمشروع.

### الخوارزميات وتقنيات المعالجة المسبقة

-   **معالجة الصور المسبقة (Image Preprocessing)**: يتم تغيير حجم الصور إلى أبعاد موحدة (224x224 بكسل) وتطبيع قيم البكسل (عادةً بين 0 و 1) قبل إدخالها إلى النموذج. كما يتم تطبيق دوال معالجة مسبقة خاصة بالنموذج الأساسي (مثل `preprocess_input` لـ `MobileNet`) لضبط قيم البكسل بما يتوافق مع التدريب الأصلي للنموذج.
-   **زيادة البيانات (Data Augmentation)**: لزيادة قوة النموذج وتقليل الإفراط في التخصيص، يتم تطبيق تقنيات زيادة البيانات على مجموعة التدريب. تشمل هذه التقنيات: الدوران، الإزاحة، القص، التكبير، وتغيير السطوع، والتقليب الأفقي والرأسي.
-   **تحسين (Optimization)**: يتم استخدام مُحسّنات مثل `Adam` أو `RMSprop` مع معدل تعلم قابل للتعديل لتحسين عملية التدريب.
-   **دالة الخسارة (Loss Function)**: يتم استخدام `Categorical Cross-Entropy` كدالة خسارة، وهي مناسبة لمهام التصنيف متعدد الفئات.

### بنية مدير التصنيف (EnhancedClassificationManager)

تم تصميم `EnhancedClassificationManager` في `enhanced_manager.py` ليكون قادرًا على إدارة نماذج تصنيف متعددة بشكل فعال. يتميز بالآتي:

-   **تحميل النماذج**: يقوم بتحميل النماذج المدربة مسبقًا لكل فئة (traffic, fire, accident, violence) من مسارات محددة.
-   **نماذج وهمية (Mock Models)**: في حالة عدم توفر نماذج حقيقية (لأغراض التطوير أو الاختبار)، يقوم بإنشاء نماذج وهمية تُرجع نتائج عشوائية، مما يضمن استمرارية عمل النظام.
-   **معالجة متوازية**: يستخدم `ThreadPoolExecutor` لتصنيف الصورة عبر جميع الفئات الممكنة بشكل متوازٍ، مما يقلل بشكل كبير من زمن المعالجة الإجمالي.
-   **تحديد مستوى الخطر**: يقوم بتحديد مستوى الخطر الإجمالي للصورة بناءً على نتائج التصنيف الفردية (منخفض، متوسط، عالي، حرج).
-   **توليد التنبيهات**: بناءً على مستوى الخطر ونتائج التصنيف، يقوم بتوليد رسائل تنبيه محددة.

تضمن هذه البنية المرونة، وقابلية التوسع، والكفاءة في معالجة وتحليل الصور، مما يجعل النظام قادرًا على التعامل مع مجموعة واسعة من سيناريوهات المراقبة.

## خطوات التشغيل

لتشغيل نظام الإنذار والأمان الذكي المحسن، اتبع الخطوات التالية:

### 1. المتطلبات الأساسية

تأكد من تثبيت Python 3.8+ على نظامك. يفضل استخدام بيئة افتراضية لإدارة التبعيات.

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. تثبيت المكتبات

انتقل إلى مجلد المشروع الرئيسي (حيث يوجد ملف `requirements.txt`) وقم بتثبيت جميع المكتبات المطلوبة:

```bash
pip install -r requirements.txt
```

### 3. إعداد متغيرات البيئة

قم بإنشاء ملف `.env` في المجلد الرئيسي للمشروع بناءً على ملف `.env.example`، وقم بتعديل القيم حسب الحاجة. هذا الملف يحتوي على إعدادات حساسة مثل مفتاح JWT السري، ومعلومات قاعدة البيانات، وإعدادات البريد الإلكتروني.

```bash
cp .env.example .env
```

**مثال على محتويات ملف `.env`:**

```
SECRET_KEY="your_super_secret_key_for_jwt"
DATABASE_URL="sqlite:///site.db"
MAIL_SERVER="smtp.gmail.com"
MAIL_PORT=587
MAIL_USE_TLS=True
MAIL_USERNAME="your_email@example.com"
MAIL_PASSWORD="your_email_password"
ADMIN_EMAIL="admin@example.com"
UPLOAD_FOLDER="uploads"
MAX_CONTENT_LENGTH=33554432
```

### 4. تشغيل الخادم الخلفي (API)

بعد تثبيت المتطلبات وإعداد ملف `.env`، يمكنك تشغيل الخادم الخلفي. انتقل إلى مجلد `backend` وقم بتشغيل الملف الرئيسي:

```bash
cd backend
python3 app.py
```

سيتم تشغيل الخادم على المنفذ الافتراضي 5000 (http://127.0.0.1:5000).

إذا لم تكن نماذج التصنيف الحقيقية متوفرة في مجلد `models`، فسيقوم النظام تلقائيًا باستخدام نماذج وهمية لأغراض الاختبار والتطوير.

### 5. تشغيل الواجهة الأمامية (Frontend)

الواجهة الأمامية هي تطبيق ويب ثابت يعتمد على HTML، CSS، و JavaScript. لتشغيلها:

1.  انتقل إلى مجلد `frontend`:
    ```bash
    cd ../frontend
    ```
2.  قم بتشغيل خادم HTTP بسيط (يمكنك استخدام أي خادم ويب ثابت، مثل `http.server` في Python):
    ```bash
    python3 -m http.server 8080
    ```
3.  افتح متصفح الويب الخاص بك وانتقل إلى العنوان: `http://localhost:8080`.

تأكد من أن `API_BASE_URL` في ملف `frontend/js/api.js` يشير إلى العنوان الصحيح للخادم الخلفي (  http://localhost:5000/`).


## النتائج

تم تصميم النظام لتحقيق دقة عالية في التصنيف مع توفير معلومات مفصلة حول كل حدث مكتشف. تعتمد النتائج بشكل كبير على جودة البيانات المستخدمة للتدريب وقوة النماذج المختارة. فيما يلي ملخص للنتائج المتوقعة والتحليلات:

### 1. دقة التصنيف (Accuracy)

بناءً على ملفات Jupyter Notebook المرفقة والنهج المتبع في التعلم بالنقل، من المتوقع أن تحقق النماذج دقة عالية في تصنيف الفئات المستهدفة. نموذج العنف ونموذج الفئات الأخرى (حركات المرور، الحرائق، الحوادث) اللذان يستخدمان `MobileNet`، بعد تطبيق تقنيات زيادة البيانات والتدريب على مرحلتين، يمكن أن يصل إلى دقة تتجاوز 95% على مجموعات الاختبار.

**مثال على الدقة المتوقعة:**

| الفئة            | النموذج المستخدم | الدقة المتوقعة |
| :--------------- | :--------------- | :------------- |
| العنف            | MobileNet        | 91% - 93%      |
| حركات المرور     | MobileNet        | 95% - 97%      |
| الحرائق          | MobileNet        | 95% - 97%      |
| الحوادث          | MobileNet        | 95% - 97%      |

### 2. مصفوفة الالتباس (Confusion Matrix)

تعتبر مصفوفة الالتباس أداة حاسمة لتقييم أداء نماذج التصنيف، حيث توضح عدد التنبؤات الصحيحة والخاطئة لكل فئة. على سبيل المثال، لنموذج العنف (Violence Classification)، قد تبدو مصفوفة الالتباس كالتالي:

|             | تنبؤ: عنف | تنبؤ: لا عنف |
| :---------- | :-------- | :---------- |
| **حقيقي: عنف**    | 850       | 50          |
| **حقيقي: لا عنف** | 30        | 970         |

**تحليل:**
-   **True Positives (TP)**: 850 حالة عنف تم تصنيفها بشكل صحيح على أنها عنف.
-   **True Negatives (TN)**: 970 حالة لا عنف تم تصنيفها بشكل صحيح على أنها لا عنف.
-   **False Positives (FP)**: 30 حالة لا عنف تم تصنيفها بشكل خاطئ على أنها عنف (خطأ من النوع الأول).
-   **False Negatives (FN)**: 50 حالة عنف تم تصنيفها بشكل خاطئ على أنها لا عنف (خطأ من النوع الثاني).

من المهم تقليل `False Negatives` في أنظمة الأمان، حيث يعني ذلك عدم اكتشاف حدث خطير. بينما `False Positives` قد يؤدي إلى تنبيهات خاطئة ولكنها أقل خطورة.

### 3. صور مفصلة للنتائج (أمثلة)

عند تحليل صورة، يقوم النظام بإرجاع نتائج مفصلة لكل فئة تم تصنيفها، بما في ذلك مستوى الثقة ومستوى الخطر. على سبيل المثال:

**صورة تحتوي على حريق:**

```json
{
  "overall_risk": "high",
  "processing_time": 0.85,
  "image_info": {
    "path": "fire_incident_001.jpg",
    "size": [1080, 1920, 3],
    "file_size": 250000
  },
  "alerts_triggered": [
    "تنبيه fire: تم اكتشاف large_fire بثقة 96.25%"
  ],
  "results": [
    {
      "category": "fire",
      "class_name": "large_fire",
      "confidence": 0.9625,
      "risk_level": "high",
      "details": {
        "all_predictions": {"no_fire": 0.01, "smoke": 0.02, "small_fire": 0.0075, "large_fire": 0.9625},
        "model_config": {"input_size": [224, 224], "preprocess_type": "mobilenet"}
      }
    },
    {
      "category": "traffic",
      "class_name": "normal_traffic",
      "confidence": 0.85,
      "risk_level": "low",
      "details": {}
    }
  ]
}
```

**صورة تحتوي على حادث مروري:**

```json
{
  "overall_risk": "medium",
  "processing_time": 0.72,
  "image_info": {
    "path": "traffic_accident_005.jpg",
    "size": [720, 1280, 3],
    "file_size": 180000
  },
  "alerts_triggered": [
    "تنبيه accident: تم اكتشاف minor_accident بثقة 88.10%"
  ],
  "results": [
    {
      "category": "accident",
      "class_name": "minor_accident",
      "confidence": 0.8810,
      "risk_level": "medium",
      "details": {
        "all_predictions": {"no_accident": 0.10, "minor_accident": 0.8810, "major_accident": 0.019},
        "model_config": {"input_size": [224, 224], "preprocess_type": "mobilenet"}
      }
    },
    {
      "category": "violence",
      "class_name": "non_violence",
      "confidence": 0.99,
      "risk_level": "low",
      "details": {}
    }
  ]
}
```

توضح هذه الأمثلة كيف يقوم النظام بتحديد الفئات المختلفة، وتقدير الثقة، وتحديد مستوى الخطر، وتوليد التنبيهات ذات الصلة. هذه المعلومات حيوية لاتخاذ قرارات سريعة ومستنيرة في حالات الطوارئ.

## التحسينات الممكنة مستقبلاً

على الرغم من أن النظام الحالي يوفر حلاً قويًا وفعالًا، إلا أن هناك دائمًا مجالًا للتحسين والتطوير المستمر لزيادة كفاءته، ودقته، وقدراته. فيما يلي بعض التحسينات المقترحة للمستقبل:

### 1. تحسين النماذج والخوارزميات

-   **نماذج أكثر تعقيدًا**: استكشاف استخدام نماذج تعلم عميق أحدث وأكثر قوة مثل EfficientNet, Vision Transformers (ViT) لتحسين الدقة والتعامل مع سيناريوهات أكثر تعقيدًا.
-   **التعلم متعدد المهام (Multi-task Learning)**: تدريب نموذج واحد على تصنيف جميع الفئات الأربعة في نفس الوقت، مما قد يؤدي إلى تحسين الكفاءة وتعميم أفضل للميزات.
-   **التعلم المستمر (Continual Learning)**: تطوير آليات تسمح للنماذج بالتعلم من بيانات جديدة دون نسيان المعرفة المكتسبة سابقًا، مما يتيح تحديث النماذج باستمرار مع ظهور أنواع جديدة من الأحداث أو تغير الظروف.
-   **الكشف عن الكائنات (Object Detection)**: بدلاً من مجرد تصنيف الصورة ككل، يمكن دمج نماذج الكشف عن الكائنات (مثل YOLO, Faster R-CNN) لتحديد موقع الكائنات ذات الصلة (مثل السيارات، الأشخاص، النار) داخل الصورة، مما يوفر معلومات مكانية أكثر دقة.
-   **تحليل الفيديو (Video Analysis)**: توسيع قدرات النظام ليشمل تحليل تدفقات الفيديو مباشرة، وليس فقط الصور الثابتة. يتطلب ذلك استخدام نماذج شبكات عصبية تلافيفية ثلاثية الأبعاد (3D CNNs) أو شبكات عصبية متكررة (Recurrent Neural Networks - RNNs) لالتقاط المعلومات الزمنية.

### 2. تحسينات الأداء وقابلية التوسع

-   **التسريع باستخدام الأجهزة (Hardware Acceleration)**: الاستفادة من وحدات معالجة الرسوميات (GPUs) أو وحدات معالجة التنسور (TPUs) لتسريع عملية تدريب واستدلال النماذج، خاصة في بيئات الإنتاج التي تتطلب معالجة كميات كبيرة من البيانات في الوقت الفعلي.
-   **الحوسبة السحابية (Cloud Computing)**: نشر النظام على منصات الحوسبة السحابية (مثل AWS, Google Cloud, Azure) للاستفادة من مواردها المرنة والقابلة للتوسع، مما يضمن قدرة النظام على التعامل مع أي حجم من حركة المرور أو البيانات.
-   **تحسين الكفاءة**: تطبيق تقنيات تقليل حجم النموذج (Model Quantization, Pruning) لتقليل استهلاك الذاكرة وتسريع الاستدلال على الأجهزة ذات الموارد المحدودة.

### 3. تعزيز التنبيهات والإشعارات

-   **تنبيهات صوتية مخصصة**: إضافة خيارات لتخصيص التنبيهات الصوتية بناءً على نوع الحدث ومستوى الخطورة.
-   **التكامل مع أنظمة الطوارئ**: ربط النظام مباشرة بأنظمة الطوارئ المحلية (مثل أنظمة CAD للشرطة والإطفاء) لإرسال التنبيهات بشكل آلي ومباشر.
-   **خرائط تفاعلية**: دمج خرائط تفاعلية في واجهة المستخدم لعرض موقع الحدث بدقة وتوجيه فرق الاستجابة.
-   **تنبيهات متعددة اللغات**: دعم إرسال التنبيهات بلغات مختلفة لتناسب المستخدمين المتنوعين.

### 4. تحسينات واجهة المستخدم وتجربة المستخدم

-   **لوحة تحكم متقدمة**: تطوير لوحة تحكم أكثر تفاعلية وغنية بالميزات، مع رسوم بيانية وإحصائيات في الوقت الفعلي، وإمكانيات تخصيص أوسع.
-   **تخصيص التقارير**: السماح للمستخدمين بتخصيص أنواع التقارير التي يرغبون في استلامها وتنسيقها.
-   **دعم الأجهزة المحمولة**: تطوير تطبيقات مخصصة للأجهزة المحمولة (iOS/Android) لتمكين المراقبة وإدارة التنبيهات أثناء التنقل.
-   **الوضع المظلم (Dark Mode)**: إضافة خيار الوضع المظلم لتحسين تجربة المستخدم في ظروف الإضاءة المنخفضة.

### 5. الأمان والخصوصية

-   **تشفير البيانات الشامل (End-to-End Encryption)**: تطبيق تشفير شامل لجميع البيانات المنقولة والمخزنة لضمان أقصى درجات الأمان والخصوصية.
-   **المصادقة متعددة العوامل (Multi-Factor Authentication - MFA)**: إضافة دعم للمصادقة متعددة العوامل لزيادة أمان حسابات المستخدمين.
-   **تدقيق الأمان المنتظم**: إجراء تدقيقات أمنية منتظمة واختبارات اختراق (Penetration Testing) لتحديد ومعالجة أي ثغرات أمنية محتملة.

### 6. التكامل مع أنظمة أخرى

-   **تكامل مع أنظمة إدارة المباني (BMS)**: ربط النظام بأنظمة إدارة المباني للتحكم في الأبواب، والإضاءة، وأنظمة التهوية استجابة للأحداث المكتشفة.
-   **تكامل مع أنظمة الطائرات بدون طيار (Drones)**: استخدام الطائرات بدون طيار المجهزة بكاميرات لجمع البيانات في المناطق التي يصعب الوصول إليها أو في حالات الطوارئ الكبيرة.
---
##  التقنيات المستخدمة

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)
![HTML5](https://img.shields.io/badge/HTML5-E34F26?style=for-the-badge&logo=html5&logoColor=white)
![CSS3](https://img.shields.io/badge/CSS3-1572B6?style=for-the-badge&logo=css3&logoColor=white)

---

**Developer**: Abdulaziz Alqudimi

**تاريخ الإنشاء**: 22 سبتمبر 2025

**المراجع:**
[1] Kaggle: Real Life Violence Situations Dataset. Available at: [https://www.kaggle.com/datasets/abdulmananraja/real-life-violence-situations](https://www.kaggle.com/datasets/abdulmananraja/real-life-violence-situations)
[2] Kaggle: Traffic-Net Dataset. Available at: [https://www.kaggle.com/datasets/umairshahpirzada/traffic-net](https://www.kaggle.com/datasets/umairshahpirzada/traffic-net)
[3] Keras Documentation: MobileNet. Available at: [https://keras.io/api/applications/mobilenet/](https://keras.io/api/applications/mobilenet/)
[4] Keras Documentation: ImageDataGenerator. Available at: [https://keras.io/api/preprocessing/image/#imagedatagenerator-class](https://keras.io/api/preprocessing/image/#imagedatagen-class)